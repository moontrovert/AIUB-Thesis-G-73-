@inproceedings{NIPS2012_c399862d,
 title = {ImageNet Classification with Deep Convolutional Neural Networks},
 author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
 booktitle = {Advances in Neural Information Processing Systems},
 pages = {},
 publisher = {Curran Associates, Inc.},
 volume = {25},
 year = {2012}
}

@inproceedings{WardeFarley20161AP,
  title={1 Adversarial Perturbations of Deep Neural Networks},
  author={David Warde-Farley},
  year={2016},
  url={https://api.semanticscholar.org/CorpusID:28912221}
}

@misc{yuan2018adversarial,
      title={Adversarial Examples: Attacks and Defenses for Deep Learning}, 
      author={Xiaoyong Yuan and Pan He and Qile Zhu and Xiaolin Li},
      year={2018},
      eprint={1712.07107},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}


@misc{athalye2018obfuscated,
      title={Obfuscated Gradients Give a False Sense of Security: Circumventing Defenses to Adversarial Examples}, 
      author={Anish Athalye and Nicholas Carlini and David Wagner},
      year={2018},
      eprint={1802.00420},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}



@misc{grosse2016adversarial,
      title={Adversarial Perturbations Against Deep Neural Networks for Malware Classification}, 
      author={Kathrin Grosse and Nicolas Papernot and Praveen Manoharan and Michael Backes and Patrick McDaniel},
      year={2016},
      eprint={1606.04435},
      archivePrefix={arXiv},
      primaryClass={cs.CR}
}

@article{goodfellow2018making,
  title={Making machine learning robust against adversarial inputs},
  author={Goodfellow, Ian and McDaniel, Patrick and Papernot, Nicolas},
  journal={Communications of the ACM},
  volume={61},
  number={7},
  pages={56--66},
  year={2018},
  publisher={ACM New York, NY, USA}
}


@article{45818,
title	= {Adversarial examples in the physical world},
author	= {Alexey Kurakin and Ian Goodfellow and Samy Bengio},
year	= {2017},
URL	= {https://arxiv.org/abs/1607.02533},
journal	= {ICLR Workshop}
}

@misc{goodfellow2015explaining,
      title={Explaining and Harnessing Adversarial Examples}, 
      author={Ian J. Goodfellow and Jonathon Shlens and Christian Szegedy},
      year={2015},
      eprint={1412.6572},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

@inproceedings{oquab2014learning,
  title={Learning and transferring mid-level image representations using convolutional neural networks},
  author={Oquab, Maxime and Bottou, Leon and Laptev, Ivan and Sivic, Josef},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={1717--1724},
  year={2014}
}

@misc{razavian2014cnn,
      title={CNN Features off-the-shelf: an Astounding Baseline for Recognition}, 
      author={Ali Sharif Razavian and Hossein Azizpour and Josephine Sullivan and Stefan Carlsson},
      year={2014},
      eprint={1403.6382},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@article{madry2017towards,
  title={Towards deep learning models resistant to adversarial attacks},
  author={Madry, Aleksander and Makelov, Aleksandar and Schmidt, Ludwig and Tsipras, Dimitris and Vladu, Adrian},
  journal={arXiv preprint arXiv:1706.06083},
  year={2017}
}

@misc{davchev2019empirical,
      title={An Empirical Evaluation of Adversarial Robustness under Transfer Learning}, 
      author={Todor Davchev and Timos Korres and Stathi Fotiadis and Nick Antonopoulos and Subramanian Ramamoorthy},
      year={2019},
      eprint={1905.02675},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

